

# 衡量特征工程

对于一个机器学习问题，数据和特征往往决定了结果的上限，而模型、算法的选择以及优化则时逐步接近这个上限。

**特征工程**：就是对原始数据进行一系列的处理，将其提炼为特征，作为输入提供给算法和模型使用。旨在去除原始数据中的杂质和冗余信息。

*常见的数据类型*：结构化数据和非结构化数据

## 特征归一化

为了消除数据特征之间的量纲影响，我们需要对特征进行归一化处理，使得不同的指标之间具有可比性。

* ***知识点***

    * 特征归一化

* ***问题***(★☆☆☆☆)

    * <font color=red>为什么需要对数值类型的特征做归一化？</font>

* ***分析与解答***

    对数值类型的特征做归一化可以将所有的特征都统一到一个大致相同的数值区间内

    * 线性函数归一化(Min-Max Scaling)

        对原始数据进行线性变换，使结果映射到[0，1]的范围，实现对原始数据的等比缩放
        $$
        X_{norm} = \frac{X-X_{min}}{X_{max}-X_{min}}
        $$

        * 其中$X$为原始数据，$X_{max}$、$X_{min}$分别为数据的最大值和最小值

    * 零均值归一化(Z-score Normalization)

        将原始数据映射到均值为0、标准差为1的分布上
        $$
        z = \frac{x-\mu}{\sigma}
        $$

        * 均值为$\mu$、标准差为$\sigma$

## 类别型特征

类别型特征原始市场通常是字符串形式，除了决策树等少数模型能直接处理字符串形式的输入，对于大多数模型来说，类别特征剥削经过处理转换为数值型特征才可以。

* ***知识点***

    * 序号编码(Ordinal Encoding)
    * 独热编码(One-hot Encoding)
    * 二进制编码(Binary Encoding)

* ***问题***(★★☆☆☆)

    * <font color=red>在对数据进行预处理时，应该怎样处理类别型特征？</font>

* ***分析与解答***

    * 序号编码

        序号编码常用于处理类别间具有大小关系的数据。例如成绩，可以分为低、中、高三 档，并且存在“高>中>低”的排序关系。序号编码会按照大小关系对类别型特征赋予一个数值 ID，例如高表示为3、中表示为2、低表示为1，转换后依然保留了大小关系

    * 独热编码

        ​		独热编码通常用于处理类别间不具有大小关系的特征。例如血型，一共有4个取值（A型 血、B型血、AB型血、O型血），独热编码会把血型变成一个4维稀疏向量，A型血表示为 （1, 0, 0, 0），B型血表示为（0, 1, 0, 0），AB型表示为（0, 0, 1, 0），O型血表示为（0, 0, 0, 1）。对于类别取值较多的情况下使用独热编码需要注意以下问题：

        * 使用稀疏向量来节省空间。在独热编码下，特征向量只有某一维取值为1，其他位 置取值均为0。因此可以利用向量的稀疏表示有效地节省空间，并且目前大部分的算法均接 受稀疏向量形式的输入
        * 配合特征选择来降低维度。高维度特征会带来几方面的问题。
            * 一是在K近邻算法中，高维空间下两点之间的距离很难得到有效的衡量
            * 二是在逻辑回归模型中，参数的数量会随着维度的增高而增加，容易引起过拟合问题
            * 三是通常只有部分维度是对分类、预测有帮助，因此可以考虑配合特征选择来降低维度

    * 二进制编码

        二进制编码主要分为两步，先用序号编码给每个类别赋予一个类别ID，然后将类别ID对应的二进制编码作为结果。以A、B、AB、O血型为例，下表是二进制编码的过程。A型血的ID为1，二进制表示为001；B型血的ID为2，二进制表示为010；以此类推可以得到AB型血和O型血的二进制表示。可以看出，二进制编码本质上是利用二进制对ID进行哈希映射，最终得到0/1特征向量，且维数少于独热编码，节省了存储空间。

        ![](.\img\二进制编码与独热编码.png "二进制编码与独热编码")

        

## 高维组合特征的处理

* ***知识点***(★★☆☆☆)

    * 组合特征

* ***问题***(★★☆☆☆)

    * <font color=red>什么时组合特征？如何处理高维组合特征？</font>

* ***分析与解答***

    为了提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征两两组合，构成高阶组合特征。

    * 例：以逻辑回归为例，假设数据的特征向量为X=(x1,x2,...,xk )，则有：
        $$
        Y = sigmoid(\sum\limits_{i}\sum\limits_{j}w_{ij}<x_i,y_j>)
        $$
        其中$<x_i,y_j>$表示$x_i$和$x_j$的组合特征，$w_{ij}$的维度等于$|x_i|.|x_j|$分别代表第$i$个特征和第$j$个特征不同取值个数。

    

    若用户的数量为$m$、物品的数量为$n$，那么需要学习的参数的规模为$m×n$。在互联网环境 下，用户数量和物品数量都可以达到千万量级，几乎无法学习$m×n$规模的参数。在这种情况 下，一种行之有效的方法是将用户和物品分别用k维的低维向量表示$(k<<m,k<<n)$,
    $$
    Y = sigmoid(\sum\limits_{i}\sum\limits_{j}w_{ij}<x_i,y_j>)
    $$
    其中 ，$w_{ij} = x_{i}^{'}.x_{j}^{'}$,$x_{i}^{'}$和$x_{j}^{'}$分别表示$x_i$和$x_j$对应的低维向量。这其实等价于矩阵分解。

## 文本表示模型

* ***知识点***

    * 词袋模型(Bag Words)
    * TF-IDF(Term Frequency-Inverse Document)
    * 主题模型(Topic Mode)
    * 词嵌入模型(Word Embedding)

* ***问题***(★★☆☆☆)

    * <font color=red>有哪些文本表示模型？它们各有什么优点?</font>

* ***分析与解答***

    * 词袋模型和N-gram模型

        ​		最基础的文本表示模型是词袋模型。顾名思义，就是将每篇文章看成一袋子词，并忽略 每个词出现的顺序。具体地说，就是将整段文本以词为单位切分开，然后每篇文章可以表示 成一个长向量，向量中的每一维代表一个单词，而该维对应的权重则反映了这个词在原文章 中的重要程度。常用TF-IDF来计算权重，公式为
        $$
        TF-IDF(t,d) = tf(t,d)\times IDF(t)
        $$
        其中$TF(t,d)$为单纯$t$在文档$d$中出现的频率，$IDF(t)$是逆文档频率，用来衡量单词$t$对表达语义所起的重要性，表示为
        $$
        IDF(t) = log\frac{文章总数}{包含单词t的文章总数+1}
        $$
        直观的解释是，如果一个单词在非常多的文章里面都出现，那么它可能是一个比较通用的词 汇，对于区分某篇文章特殊语义的贡献较小，因此对权重做一定惩罚。

        ​		将文章进行单词级别的划分有时候并不是一种好的做法，比如英文中的natural language processing（自然语言处理）一词，如果将natural，language，processing这3个词拆分开来， 所表达的含义与三个词连续出现时大相径庭。通常，可以将连续出现的n个词（n≤N）组成的 词组（N-gram）也作为一个单独的特征放到向量表示中去，构成N-gram模型。另外，同一个词可能有多种词性变化，却具有相似的含义。在实际应用中，一般会对单词进行词干抽取（Word Stemming）处理，即将不同词性的单词统一成为同一词干的形式。

    * 主题模型

        主题模型用于从文本库中发现有代表性的主题（得到每个主题上面词的分布特性），并 且能够计算出每篇文章的主题分布，具体细节参见**概率图模型$\rightarrow$主题模型。**

    * 词嵌入与深度学习模型

        ​		词嵌入是一类将词向量化的模型的统称，核心思想是将每个词都映射成低维空间（通常K=50～300维）上的一个稠密向量（Dense Vector）。K维空间的每一维也可以看作一个隐含的主题，只不过不像主题模型中的主题那样直观。

        ​		由于词嵌入将每个词映射成一个K维的向量，如果一篇文档有N个词，就可以用一个N×K 维的矩阵来表示这篇文档，但是这样的表示过于底层。在实际应用中，如果仅仅把这个矩阵 作为原文本的表示特征输入到机器学习模型中，通常很难得到令人满意的结果。因此，还需要在此基础之上加工出更高层的特征。在传统的浅层机器学习模型中，一个好的特征工程往往可以带来算法效果的显著提升。而深度学习模型正好为我们提供了一种自动地进行特征工程的方式，模型中的每个隐层都可以认为对应着不同抽象层次的特征。从这个角度来讲，深度学习模型能够打败浅层模型也就顺理成章了。卷积神经网络和循环神经网络的结构在文本 表示中取得了很好的效果，主要是由于它们能够更好地对文本进行建模，抽取出一些高层的语义特征。与全连接的网络结构相比，卷积神经网络和循环神经网络一方面很好地抓住了文本的特性，另一方面又减少了网络中待学习的参数，提高了训练速度，并且降低了过拟合的风险。

## Word2Vec

WordVec是谷歌2013年提出来的，母亲是最常用的词嵌入模型之一，WordVec实际是一种浅层神经网络模型，它有两种网络结构：CBOW(Continues Bag of Words)、Skipgram

* ***知识点***

    * WordVec
    * 隐狄利克雷模型(LDA)
    * CBOW
    * Skip-gram

* ***问题***(★★★☆☆)

    * <font color=red>Word2Vec是如何工作的？它和LDA有什么区别与联系？</font>

* ***分析与解答***

    ​		CBOW的目标是根据上下文出现的词语来预测当前词的生成概率，如图a；而Skip-gram是根据当前词来预测上下文中各词的生成概率，如图b。

    ![Word2Vec的两种网络结构](.\img\Word2Vec的两种网络结构.png "Word2Vec的两种网络结构")

    ​		其中w(t)是当前所关注的词，w(t−2)、w(t−1)、w(t+1)、w(t+2)是上下文中出现的词。这里前后滑动窗口大小均设为2。

    ​		CBOW和Skip-gram都可以表示成由输入层（Input）、映射层（Projection）和输出层 （Output）组成的神经网络。

    ​		输入层中的每个词由独热编码方式表示，即所有词均表示成一个N维向量，其中N为词汇表中单词的总数。在向量中，每个词都将与之对应的维度置为1，其余维度的值均设为0。 

    ​		在映射层（又称隐含层）中，K个隐含单元（Hidden Units）的取值可以由N维输入向量以及连接输入和隐含单元之间的N×K维权重矩阵计算得到。在CBOW中，还需要将各个输入词所计算出的隐含单元求和。 

    ​		在输出层向量的值可以通过隐含层向量（K维），以及连接隐含层和输出层之间的 K×N维权重矩阵计算得到。输出层也是一个N维向量，每维与词汇表中的一个单词相对应。最后，对输出层向量应用Softmax激活函数，可以计算出每个单词的生成概率。Softmax激活函数的定义为：
    $$
    P(y=w_n|x)=\frac{e^{x_n}}{\sum\limits_{k=1}^{N}e^{x_k}}
    $$
    其中$x$代表N维的原始输出向量，$x_n$为在原始输出向量中，与单词$w_n$所对应维度的取值。

    ​		接下来的任务就是训练神经网络的权重，使得语料库中所有单词的整体生成概率最大化。从输入层到隐含层需要一个维度为N×K的权重矩阵，从隐含层到输出层又需要一个维度为K×N的权重矩阵，学习权重可以用反向传播算法实现，每次迭代时将权重沿梯度更优的方向进行一小步更新。但是由于Softmax激活函数中存在归一化项的缘故，推导出来的迭代公式需要对词汇表中的所有单词进行遍历，使得每次迭代过程非常缓慢，由此产生了Hierarchical Softmax和Negative Sampling两种改进方法。训练得到维度为N×K和K×N的两个权重矩阵之后，可以选择其中一个作为N个词的K维向量表示。

    ​		谈到Word2Vec与LDA的区别和联系，首先，LDA是利用文档中单词的共现关系来对单词按主题聚类，也可以理解为对“文档-单词”矩阵进行分解，得到“文档-主题”和“主题-单词”两个概率分布。而Word2Vec其实是对“上下文-单词”矩阵进行学习，其中上下文由周围的几个单词组成，由此得到的词向量表示更多地融入了上下文共现的特征。也就是说，如果两个单词所对应的Word2Vec向量相似度较高，那么它们很可能经常在同样的上下文中出现。需要说明的是，上述分析的是LDA与Word2Vec的不同，不应该作为主题模型和词嵌入两类方法的主要差异。主题模型通过一定的结构调整可以基于“上下文-单词”矩阵进行主题推理。同样地，词嵌入方法也可以根据“文档-单词”矩阵学习出词的隐含向量表示。主题模型和词嵌入两类方法最大的不同其实在于模型本身，主题模型是一种基于概率图模型的生成式模型，其似然函数可以写成若干条件概率连乘的形式，其中包括需要推测的隐含变量（即主题）；而 词嵌入模型一般表达为神经网络的形式，似然函数定义在网络的输出之上，需要通过学习网络的权重以得到单词的稠密向量表示。

    

## 图像数据不足时的处理办法

* ***知识点***

    * 迁移学习（Transfer Learning）
    * 生成对抗网络
    * 图像处理
    * 上采样技术
    * 数据扩充

* ***问题***(★★★☆☆)

    * <font color=red>在图像分类任务中，训练数据不足会带来什么问题？如何缓解数据量不足带来的问题？</font>

* ***分析与解答***

    ​		一个模型所能提供的信息一般来源于两个方面，一是训练数据中蕴含的信息；二是在模型的形成过程中(包括构造、学习、推理等)，人们提供的先验信息。当训练数据不足时，说明模型从原始数据中获取的信息比较少，这种情况下要想保证模型的效果，就需要更多先验信息。先验信息可以作用在模型上，例如让模型采用特定的内在结构、条件假设或添加其他一些约束条件；先验信息也可以直接施加在数据集上，即根据特定的先验假设去调整、变换或扩展训练数据，让其展现出更多的、更有用的信息，以利于后续模型的训练和学习。

    ​		具体到图像分类任务上，训练数据不足带来的问题主要表现在过拟合方面，即模型在训练样本上的效果可能不错，但在测试集上的泛化效果不佳。根据上述讨论，对应的处理方法大致也可以分两类，一是基于模型的方法，主要是采用降低过拟合风险的措施，包括简化模型（如将非线性模型简化为线性模型）、添加约束项以缩小假设空间（如$L_1/L_2$正则项）、 集成学习、Dropout超参数等；二是基于数据的方法，主要通过数据扩充（Data Augmentation），即根据一些先验知识，在保持特定信息的前提下，对原始数据进行适当变换以达到扩充数据集的效果。具体到图像分类任务中，在保持图像类别不变的前提下，可以对训练集中的每幅图像进行以下变换:

    * 一定程度内的随机旋转、平移、缩放、裁剪、填充、左右翻转等，这些变换对应着同一个目标在不同角度的观察结果。 
    * 对图像中的像素添加噪声扰动,比如椒盐噪声、高斯白噪声等。 
    * 颜色变换。例如，在图像的RGB颜色空间上进行主成分分析，得到3个主成分的特征向量$p_1,p_2,p_3$及其对应的特征值 $λ_1,λ_2,λ_3$，然后在每个像素的RGB值上添加增量 $[p_1,p_2,p_3]•[α_1λ_1,α_2λ_2,α_3λ_3]^T$，其中 $α_1,α_2,α_3$是均值为0、方差较小的高斯分布随机数。 
    * 改变图像的亮度、清晰度、对比度、锐度等。

    ​		除了直接在图像空间进行变换，还可以先对图像进行特征提取，然后在图像的特征空间内进行变换，利用一些通用的数据扩充或上采样技术，例如SMOTE(Synthetic Minority Over-sampling Technique)算法。抛开上述这些启发式的变换方法，使用生成模型也可以合成一些新样本，例如当今非常流行的生成式对抗网络模型。

    ​		此外，借助已有的其他模型或数据来进行迁移学习在深度学习中也十分常见。例如，对 于大部分图像分类任务，并不需要从头开始训练模型，而是借用一个在大规模数据集上预训 练好的通用模型，并在针对目标任务的小数据集上进行微调（fine-tune），这种微调操作就可以看成是一种简单的迁移学习。

# 模型评估

## 评价指标的局限性

在模型评估过程中，分类问题、排序问题、回归问题往往需要使用补贴的指标进行评估，在诸多评估的指标中，大部分指标只能片面地反映模型的一部分性能。

* ***知识点***

    * 准确率(Accuracy)
    * 精确率(Precision)
    * 召回率(Recall)
    * 均方根误差(Root Mean Square Error，*RMSE*)

* ***问题1***(★☆☆☆☆)

    * <font color=red>准确率的局限性</font>

* ***分析与解答***

    准确率是指分类正确的样本占总样本个数的比例：
    $$
    Accuracty = \frac{n_{correct}}{n_{total}}
    $$
    其中$n_{correct}$为被正确分类的样本个数，$n_{total}$为总样本个数。

    ​		准确率是分类问题中最简单也是最直观的评价指标，但是存在明显的缺陷，例如：当负样本站99%时，分类器把所有样本都预测为负样本也可以获得99%的准确率，所以，当不同样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。

* ***问题2***(★☆☆☆☆)

    * <font color=red>精确率与召回率的权衡</font>

* ***分析与解答***

    * 精确率：分类正确的正样本个数占分类器判定为正样本的样本个数的比例

    * 召回率：分类正确的正样本个数占真正的正样本个数的比例

    通常没有一个确定的阈值把得到的结果直接判定为正样本或负样本，儿是采用Top N返回结果的Precision值和Recall值来衡量分类模型的性能，即认为模型返回的Top N 的结果就是模型判定的正样本，然后计算前N个位置上的准确率Precision N和前N个位置上的召回率Recall N
    
    ​		Precision值和Recall值是既矛盾又统一的两个指标，为了提高Precision值，分类器需要尽量在"更有把握"时才把样本预测为正样本，但是此时往往会因为过于保守而漏掉很多"没有把握"的正样本，导致Recall值降低。
    
    ​		除此之外F1-score和ROC曲线也能综合地反映一个分类模型的性能，F1-score是精确率和召回率的调和平均值：
    $$
    F1 = \frac{2\times precision\times recall}{precision + recall}
    $$
    
* ***问题3***(★☆☆☆☆)

    * <font color=red>平方根误差</font>

* ***分析与解答***

  RMSE经常被用来衡量回归模型的好坏,但是有时这个指标会失效。
  $$
  RMSE = \sqrt{\frac{\sum\limits_{i=1}^{n}(y_i -\hat{y_i})}{n}}
  $$
  其中，$y_i$是第i个样本点的真实值,$\hat{y_i}$是第$i$个样本点的预测值，n是样本点的个数
  
  ​		一般情况下，RMSE能够很好地反映回归模型预测值与真实值的偏离程度。但在实际问题中，如果存在个别偏离程度非常大的离群点（Outlier）时，即使离群点数量非常少，也会让RMSE指标变得很差。
  
  ​	**解决：**
  
  * 如果我们认定这些离群点是“噪声点”的话，就需要在数据预处理的阶段把这些噪声点过滤掉
  
  * 如果不认为这些离群点是“噪声点”的话，就需要进一步提高模型的预测能力，将离群点产生的机制建模进去
  
  * 可以找一个更合适的指标来评估该模型。关于评估指标，其实是存在比RMSE的鲁棒性更好的指标，比如平均绝对百分比误差（Mean Absolute Percent Error，MAPE），它定义为：
      $$
      MAPE = \sum\limits_{i=1}^{n}|\frac{y_i - \hat{y_i}}{y_i}|\times\frac{100}{n}
      $$
      相比RMSE，MAPE相当于把每个点的误差进行了归一化，降低了个别离群点带来的绝对误差的影响。

## ROC曲线

* ***知识点***
  
* ROC曲线
    * 曲线下的面积(Aera Under Curve，AUC)
    * P-R曲线
    
* ***问题1***(★☆☆☆☆)

    * <font color=red>什么是ROC曲线？</font>

* ***分析与解答***

    ​		ROC曲线是Receiver Operating Characteristic Curve的简称，中文名为“受试者工作特征曲 线”。ROC曲线源于军事领域，而后在医学领域应用甚广，“受试者工作特征曲线”这一名称 也正是来自于医学领域。

    ​		ROC曲线的横坐标为假阳性率（False Positive Rate，FPR）；纵坐标为真阳性率（True Positive Rate，TPR）。FPR和TPR的计算方法分别为:
    $$
    FPR=\frac{FP}{N}
    $$

    $$
    TPR = \frac{TP}{P}
    $$

    $P$是真实的正样本的数量，$N$是真实的负样本的数量，$TP$是$P$个正样本中被分类器预测为正样本的个数，$FP$是$N$个负样本中被分类器预测为正样本的个数。

* ***问题2***(★★☆☆☆)

    * <font color=red>如何计算AUC？</font>

* ***分析与解答***

    ​		AUC指的是ROC曲线下的面积大小，该值能够量化地反映基于ROC曲线衡量出的模型性能。计算AUC值只需要沿着ROC横轴做积分就可以了。由于ROC曲线一般都处于 y=x这条直线的上方*如果不是的话，只要把模型预测的概率反转成1−p就可以得到一个更好 的分类器*，所以AUC的取值一般在0.5～1之间。AUC越大，说明分类器越可能把真正的正样本排在前面，分类性能越好。

## 模型评估的方法

在机器学习中，我们通常把样本分为训练集和测试集，训练集用于训练模型，测试集用于评估模型

* ***知识点***
  
* Holdout检验
    * 交叉验证
    * 自助法(Bootstrap)
    * 微积分
    
* ***问题1***(★★☆☆☆)

    * <font color=red>在模型评估过程中，有哪些主要的验证方法，它们的优缺 点是什么?</font>

* ***分析与解答***

    * Holdout检验

        Holdout 检验是最简单也是最直接的验证方法，它将原始的样本集合随机划分成训练集 和验证集两部分.*例如:对于一个点击率预测模型，我们把样本按照 70%～30% 的比例分成两部分，70% 的样本用于模型训练；30% 的样本用于模型验证，包括绘制ROC曲线、计算精确率和召回率等指标来评估模型性能。*

        **Holdout检验的缺点：**即在验证集上计算出来的最后评估指标与原始分组有很大关系

    * 交叉检验

        ​		**k-fold交叉验证：**首先将全部样本划分成k个大小相等的样本子集；依次遍历这k个子集，每次把当前子集作为验证集，其余所有子集作为训练集，进行模型的训练和评估；最后把k次评估指标的平均值作为最终的评估指标。在实际实验中，k经常取10。

        ​		**留一验证：**每次留下1个样本作为验证集，其余所有样本作为测试集。样本总数为n，依次对n个样本进行遍历，进行n次验证，再将评估指标求平均值得到最终的评估指标。在样本总数较多的情况下，留一验证法的时间开销极大。事实上，留一验证是留p验证的特例。留p验证是每次留下p个样本作为验证集，而从n个元素中选择p个元素有$C_{n}^p$种可能，因此它的时 间开销更是远远高于留一验证，故而很少在实际工程中被应用。

    * 自助法 

        ​		不管是Holdout检验还是交叉检验，都是基于划分训练集和测试集的方法进行模型评估的。然而，当样本规模比较小时，将样本集进行划分会让训练集进一步减小，这可能会影响模型训练效果。自助法*能维持训练集样本规模的验证方法*

        ​		自助法是基于自助采样法的检验方法。对于总数为$n$的样本集合，进行$n$次有放回的随机抽样，得到大小为$n$的训练集。$n$次采样过程中，有的样本会被重复采样，有的样本没有被抽 出过，将这些没有被抽出的样本作为验证集，进行模型验证，这就是自助法的验证过程。

    * ***问题2***(★★★☆☆)

        * <font color=red>在自助法的采样过程中，对n个样本进行n次自助抽样， 当n趋于无穷大时，最终有多少数据从未被选择过？</font>

    * ***分析与解答***

        一个样本在一次抽样过程中未被抽中的概率为 $(1-\frac{1}{n})$，$n$次抽样均未抽中的$(1-\frac{1}{n})^n$概率为 。当$n$趋于无穷大时，概率为$\lim\limits_{n\rightarrow\infty}(1-\frac{1}{n})^n$。 根据重要极限$\lim \limits_{n\rightarrow\infty}(1-\frac{1}{n})^n = e$，所以有 
        $$
        \lim\limits_{n\rightarrow\infty}(1-\frac{1}{n}^n)=\lim\limits_{n\rightarrow\infty}\frac{1}{(1+\frac{1}{n-1})^n}
        $$

        $$
        ={\frac{1}{\lim\limits_{n\rightarrow\infty}(1+\frac{1}{n-1})^n }. \frac{1}{\lim\limits_{n\rightarrow\infty}(1+\frac{1}{n-1})}}
        $$

        $$
        =\frac{1}{e}\approx 0.368
        $$

        因此，当样本数很大时，大约有36.8%的样本从未被选择过，可作为验证集。

## 超参数调优

需要明确超参数搜索算法一般包括哪几个要素:**一是目标函数**,即算法需 要最大化/最小化的目标；**二是搜索范围**,一般通过上限和下限来确定;**三是算法的其他参数**,如搜索步长

* ***问题***(★☆☆☆☆)

    * <font color=red>超参数有哪些调优方法？</font>

* ***分析与解答***

    * 网格搜索

        ​		网格搜索可能是最简单、应用最广泛的超参数搜索算法，它通过查找搜索范围内的所有的点来确定最优值。如果采用较大的搜索范围以及较小的步长，网格搜索有很大概率找到全局最优值。然而，这种搜索方案十分消耗计算资源和时间，特别是需要调优的超参数比较多的时候。因此，在实际应用中，网格搜索法一般会先使用较广的搜索范围和较大的步长，来寻找全局最优值可能的位置；然后会逐渐缩小搜索范围和步长，来寻找更精确的最优值。这种操作方案可以降低所需的时间和计算量，但由于目标函数一般是非凸的，所以很可能会错过全局最优值。

    * 随机搜索

        ​		随机搜索的思想与网格搜索比较相似，只是不再测试上界和下界之间的所有值，而是在搜索范围中随机选取样本点。它的理论依据是，如果样本点集足够大，那么通过随机采样也能大概率地找到全局最优值，或其近似值。随机搜索一般会比网格搜索要快一些，但是和网格搜索的快速版一样，它的结果也是没法保证的。

    * 贝叶斯优化算法

        ​		贝叶斯优化算法在寻找最优最值参数时，采用了与网格搜索、随机搜索完全不同的方法。网格搜索和随机搜索在测试一个新点时，会忽略前一个点的信息；而贝叶斯优化算法则逸闻趣事充分利用了之前的信息。贝叶斯优化算法通过对目标函数形状进行学习，找到使目标函数向全局最优值提升的参数。具体来说，它学习目标函数形状的方法是，首先根据先验分布，假设一个搜集函数；然后，每一次使用新的采样点来测试目标函数时，利用这个信息来更新目标函数的先验分布；最后，算法测试由后验分布给出的全局最值最可能出现的位置的点。对 于贝叶斯优化算法，有一个需要注意的地方，一旦找到了一个局部最优值，它会在该区域不断采样，所以很容易陷入局部最优值。为了弥补这个缺陷，贝叶斯优化算法会在探索和利用之间找到一个平衡点，“探索”就是在还未取样的区域获取采样点；而“利用”则是根据后验分布在最可能出现全局最值的区域进行采样。

## 过拟合与欠拟合

* ***知识点***
  
* 过拟合
  
    * 欠拟合
    
* ***问题1***(★☆☆☆☆)

    * <font color=red>在模型评估过程中，过拟合和欠拟合具体是指什么现象？</font>

* ***分析与解答***

    **过拟合**：是指模型对于训练数据拟合呈过当的情况，反映到评估指标上，就是模型在训练 集上的表现很好，但在测试集和新数据上的表现较差。

    **欠拟合**：欠拟合指的是模型在训练和预测时表 现都不好的情况。

    ![](\img\欠拟合&欠拟合.png"欠拟合&欠拟合")

    a:是欠拟合的情况，拟合的黄线没有很好地捕捉到数据的特征，不能够很好地拟合数据。

    c:则是过拟合的情况，模型过于复杂，把噪声数据的特征也学习到模型中，导致模型泛化能力下降，在后期应用过程中很容易输出错误的预测结果。

* ***问题2***(★★☆☆☆)

    * <font color=red>能否说出几种降低过拟合和欠拟合风险的方法？</font>

* ***分析与解答***

    * 降低“过拟合”风险的方法 

        * **从数据入手，获得更多的训练数据**。使用更多的训练数据是解决过拟合问题最有效的手段，因为更多的样本能够让模型学习到更多更有效的特征，减小噪声的影响。当然，直接增加实验数据一般是很困难的，但是可以通过一定的规则来扩充训练数据。比如，在图 像分类的问题上，可以通过图像的平移、旋转、缩放等方式扩充数据；更进一步地，可以使用生成式对抗网络来合成大量的新训练数据。

        * **降低模型复杂度**。在数据较少时，模型过于复杂是产生过拟合的主要因素，适当降低模型复杂度可以避免模型拟合过多的采样噪声。例如，在神经网络模型中减少网络层数、神经元个数等；在决策树模型中降低树的深度、进行剪枝等。

        * **正则化方法**。给模型的参数加上一定的正则约束，比如将权值的大小加入到损失函数中。以$L2$正则化为例：
            $$
            C=C_0 + \frac{\lambda}{2n}.\sum\limits_{i}w_{i}^2
            $$
            这样，在优化原来的目标函数$C_0$的同时，也能避免权值过大带来的过拟合风险

        * **集成学习方法**。集成学习是把多个模型集成在一起，来降低单一模型的过拟合风险，如Bagging方法。

    * 降低“欠拟合”风险的方法

        * **添加新特征**。当特征不足或者现有特征与样本标签的相关性不强时，模型容易出现欠拟合。通过挖掘“上下文特征”“ID类特征”“组合特征”等新的特征，往往能够取得更好的效果。在深度学习潮流中，有很多模型可以帮助完成特征工程，如因子分解机、梯度提升决策树、Deep-crossing等都可以成为丰富特征的方法。
        * **增加模型复杂度**。简单模型的学习能力较差，通过增加模型的复杂度可以使模型拥有更强的拟合能力。例如，在线性模型中添加高次项，在神经网络模型中增加网络层数或神经元个数等。
        * **减小正则化系数**。正则化是用来防止过拟合的，但当模型出现欠拟合现象时，则需要有针对性地减小正则化系数。

# 经典算法

## 支持向量机

支持向量机（Support Vector Machine，SVM）是众多监督学习方法中十分出色的一种,关于SVM，流传着一个关于天使与魔鬼的故事。

传说魔鬼和天使玩了一个游戏，魔鬼在桌上放了两种颜色的球

![](\img\分球问题1.png"分球问题1")

魔鬼让天 使用一根木棍将它们分开。这对天使来说，似乎太容易了。天使不假思索地一摆，便完成了任务

![](\img\分球问题1的简单解.png"分球问题1的简单解")

魔鬼又加入了更多的球。随着球的增多，似乎有的球不能再被原来的木棍正确分开

![](\img\分球问题2.png"分球问题2")

SVM实际上是在为天使找到木棒的最佳放置位置，使得两边的球都离分隔它们的木棒足够远

![](\img\分球问题1的优化解.png"分球问题1的优化解")

依照SVM为天使选择的木棒位置，魔鬼即使按刚才的方式继续加入新 球，木棒也能很好地将两类不同的球分开

![](\img\分球问题1的优化解面对分球问题2.png"分球问题1的优化解面对分球问题2")

看到天使已经很好地解决了用木棒线性分球的问题，魔鬼又给了天使一个新的挑战

![](\img\分球问题3.png"分球问题3")

按照这种球的摆法，世界上貌似没有一根木棒可以将它们完美分开。但天使毕竟有法力，他一拍桌子，便让这些球飞到了空中，然后凭借念力抓起一张纸片，插在了两类球的中间

![](\img\高维空间中分球问题3的解.png"高维空间中分球问题3的解")

从魔鬼的角度看这些球，则像是被一条曲线完美的切开了

![](\img\魔鬼视角下分球问题3的解.png"魔鬼视角下分球问题3的解")

后来，“无聊”的科学家们把这些球称为“数据”，把木棍称为“分类面”，找到最大间隔的 木棒位置的过程称为“优化”，拍桌子让球飞到空中的念力叫“核映射”，在空中分隔球的纸片 称为“分类超平面”

* ***知识点***
  
* SVM模型推导
    * 核函数
    * SMO(Sequential Minimal Optimization)算法
    
* ***问题1***(★★★☆☆)

    * <font color=red>在空间上线性可分的两类点，分别向SVM分类的超平面上做投影，这些点在超平面上的投影仍然是线性可分的吗？</font>

* ***分析与解答***

    ​		首先明确下问题中的概念，线性可分的两类点，即通过一个超平面可以将两类点完全分开

    ![](\img\支持向量机分类面.png"支持向量机分类面")

    ​		假设绿色的超平面（对于二维空间来说，分类超平面退化为一维直线）为 SVM算法计算得出的分类面，那么两类点就被完全分开,我们想探讨的是：*将这两类点向绿色平面上做投影，在分类直线上得到的黄棕两类投影点是否仍然线性可分*

    ![](\img\样本点在分类面上投影.png"样本点在分类面上投影")

    ​		这些点在分类超平面（绿色直线）上相互间隔，并不是线性可分的。考虑一个更简单的反例，设想二维空间中只有两个样本点，每个点各属于一类的分类任务，此时SVM的分类超平面（直线）就是两个样本点连线的中垂线，两个点在分类面（直线）上的投影会落到这条直线上的同一个点，自然不是线性可分的。

    ​		对于任意线性可分的两组点，它们在SVM分类的超平面上的投影都是线性不 可分的

    ​		由于SVM的分类超平面仅由支持向量决定（之后会证明这一结论），我们可以考虑一个只含支持向量SVM模型场景。使用反证法来证明。假设存在一个SVM分类超平面使所有支持向量在该超平面上的投影依然线性可分

    ![](\img\更优的分类超平面.png"更优的分类超平面")

    ​		根据简单的初等几何知识不难发现，图中AB两点连线的中垂线所组成的超平面（绿色虚线）是相较于绿色实线超平面更优的解，这与之前假设绿色实线超平面为最优的解相矛盾。考虑最优解对应的绿色虚线，两组点经过投影后，并不是线性可分的。

    ​		我们的证明目前还有不严谨之处，即我们假设了仅有支持向量的情况，会不会在超平面的变换过程中支持向量发生了改变，原先的非支持向量和支持向量发生了转化呢？下面我们证明SVM的分类结果仅依赖于支持向量。考虑SVM推导中的KKT条件要求:
    $$
    \nabla_wL(\omega^*,\beta^*,\alpha^*)=\omega^* - \sum\limits_{i=1}^{N}\alpha_{i}^* y_i x_i=0
    $$

    $$
    \nabla_wL(\omega^*,\beta^*,\alpha^*)= - \sum\limits_{i=1}^{N}\alpha_{i}^* y_i x_i=0
    $$

    $$
    \alpha_{i}^*g_i(\omega^*)=0,i=1,...,N
    $$

    $$
    g_i(\omega^*)\leq0,i=1,...,N
    $$

    $$
    \alpha_{i}^*\geq0 ,i=1,...,N
    $$

    结合式（20）和式（21）两个条件不难发现，当$g_i(\omega^*)<0$时，必有$\alpha_{i}^*=0$ ，将这一结果与拉格朗日对偶优化问题的公式相比较:
    $$
    \nabla_wL(\omega^*,\beta^*,\alpha^*)=\frac{1}{2}(\omega^*)^2 + \sum\limits_{i=1}^{N}\alpha_{i}^* y_i x_i
    $$
    其中：
    $$
    g_i(\omega^*)=-y_i(\omega^*.x_i+\beta^*)+1
    $$
    ​		可以看到，除支持向量外，其他系数均为0，因此SVM的分类结果与仅使用支持向量的分类结果一致，说明SVM的分类结果仅依赖于支持向量，这也是SVM拥有极高运行效率的关键之一。于是，我们证明了对于任意线性可分的两组点，它们在SVM分类的超平面上的投影都是线性不可分的。

    ​		实际上，该问题也可以通过凸优化理论中的超平面分离定理(*Separating Hyperplane Theorem*，SHT)更加轻巧地解决。该定理描述的是，对于不相交的两个凸集，存在一个超 平面，将两个凸集分离。对于二维的情况，两个凸集间距离最短两点连线的中垂线就是一个将它们分离的超平面。

    ​		借助这个定理，我们可以先对线性可分的这两组点求各自的凸包。不难发现，SVM求得的超平面就是两个凸包上距离最短的两点连线的中垂线，也就是SHT定理二维情况中所阐释的分类超平面。根据凸包的性质容易知道，凸包上的点要么是样本点，要么处于两个a样本点的连线上。因此，两个凸包间距离最短的两个点可以分为三种情况:

    **两边的点均为样本点**

    **两边的点均在样本点的连线上**

    **一边的点为样本 点，另一边的点在样本点的连线上**

    ![](\img\两个凸包上距离最短的两个点对应的三种情况.png"两个凸包上距离最短的两个点对应的三种情况")

* ***问题2***(★★★☆☆)

    * <font color=red>是否存在一组参数使SVM训练误差为0？</font>

        一个使用高斯核$(K(x,z)=e-||x-z||^{\frac{2}{r^2}})$训练的SVM中，试证明若给定训练集中不存在两个点在同一位置，则存在一组参数${α_1,...,α_m,b}$以及参数$γ$使得该SVM的训练误差为0。
    
    ***分析与解答***
    
    ​	根据SVM原理，将SVM的预测公式写为：
    $$
    f(x) = \sum\limits_{i=1}^{m}\alpha_iy^{(i)}K(x^{i},x)+b
    $$
    ​		其中$((x^{1},y^{(1)}),...,(x^{m},y^{(m)})$为训练样本，而${\alpha_1,...,\alpha_m,b}$以及高斯核参数$\gamma$为训练样本参数，由于不存在两个点在同一位置，因此对于 任意的$i≠j$，有$x^{(i)}-x^{(i)}\geq\varepsilon$。我们可以对任意$i$，固定$\alpha=1$以及$b=0$，只保留参数$\gamma$，则有:
    $$
    f(x)=\sum\limits_{i=1}^{m}\alpha_iy^{(i)}K(x^{(i)},x)+b
    \\
    =\sum\limits_{i=1}^{m}\alpha_iy^{(i)}K(x^{(i)},x)
    \\=\sum\limits_{i=1}^{m}y^{(i)}e^{-\frac{||x-x^{(i)}||^{2}}{\gamma^2}}
    $$
    将任意$x^{(j)}$代入式(26)则有:
    $$
    f(x^{(j)})=\sum\limits_{i=1}^{m}y^{(i)}e^{-\frac{||x-x^{(i)}||^{2}}{\gamma^2}}
    $$
    
    $$
    f(x^{(j)})-y^{(j)}=\sum\limits_{i=1,i\neq j}^{m}y^{(i)}e^{-\frac{||x-x^{(i)}||^{2}}{\gamma^2}}
    $$
    
    $$
    ||f(x^{(j)})-y^{(j)}||\leq\sum\limits_{i=1,i\neq j}^{m}y^{(i)}e^{-\frac{||x-x^{(i)}||^{2}}{\gamma^2}}
    $$
    
    ​	由题意知$||x^{(i)}-x^{(i)}||\geq \varepsilon$,取$\gamma=\frac{\varepsilon}{\sqrt{(log^m)}}$,可将(29)重写为：
    $$
    ||f(x^{(i)})-y^{(i)}||\leq||\sum\limits_{(i=1,i\neq j)}^{m}e^{-\frac{{||x^{(j)}-x^{(i)}||}^2}{\gamma^2}}||\\=||\sum\limits_{(i=1,i\neq j)}^{m}e^{-log^m}||\\=\frac{m-1}{m}<1
    $$
    ​	所以，对于任意$x^{(j)}$，预测结果$f(x^{(j)})$与样本真实标签$y^{(j)}$的距离小于1。注意到，$y^{(j)}\in\{1,−1\}$，当训练样本为正例，即$y^{(i)}=1$时，预测结果$f(x^{(j)})>0$， 样本被预测为正例；而当训练样本为负例，即$y^{(j)}=-1$时，预测结果$f(x^{(j)})<0$，样本被预测为负例。因此所有样本的类别都被正确预测，训练误差为0。
    
* ***问题3***(★★★★☆)

    * <font color=red>训练误差为0的SVM分类器一定存在吗？</font>

        ​	虽然在**问题2**中我们找到了一组参数${α_1,...,α_m,b}$以及$γ$使得SVM的训练误差为0，但这组参数不一定是满足SVM条件的一个解。在实际训练一个不加入松弛变量的SVM模型时，是否能保证得到的SVM分类器满足训练误差为0呢？

* ***分析与解答***

    ​	**问题2**找到了一组参数使得SVM分类器的训练误差为0。本问旨在找到一组参数满足训练误差为0，且是SVM模型的一个解。

    ​	考虑SVM模型中解的限制条件$y^{(i)}f(x^{(j)})\geq1$。我们已经得到了一组参数使得当$y^{(j)}=1$时，$f(x^{(j)})> 0$；而当$y^{(j)}=-1$时，$f(x^{(j)})<0$。现在需要找到一组参数满足更强的条件，即:
    $$
    y^{(j)}.f(x^{(j)})\geq1
    $$
    ​	仍然固定$b=0$，于是预测公式$f(x)=\sum\limits_{i=1}^{m}K(x^{(i)},x)$,将$y^{(i)}f(x^{(j)})$展开，有：
    $$
    y^{(j)}.f(x^{(j)})=y^{(j)}\alpha_iy^{(i)}K(x^{(i)},x^{(j)})\\=\alpha_iy^{(j)}K(x^{(j)},x^{(j)})+\sum\limits_{i=1,i\neq j}^{m}\alpha_iy^{(i)}y^{(j)}K(x^{(i)},x^{(j)})\\=\alpha_j +\sum\limits_{i=1,i\neq xj}^{m}\alpha_iy^{(i)}y^{(j)}K(x^{(i)},x^{(j)})
    $$
    ​	观察式(32)，可以把每个$α_j$都选择一个很大的值，同时取一个非常小的$γ$，使得核映射项$K(x^{(i)},x^{(j)})$非常小，于是$a_j$在上式中占据绝对主导地位。这样就保证对任意$j$有$y^{(j)}f(x^{(j)})>1$，满足SVM解的条件。因此SVM最优解也满足上述条件，同时 一定使模型分类误差为0。

* ***问题4***(★★★☆☆)

    * <font color=red>加入松弛变量的SVM的训练误差可以为0吗？</font>

        在实际应用中，如果使用SMO算法来训练一个加入松弛变量的线性SVM模型，并且惩罚因子$C$为任一未知常数，我们是否能得到训练误差为0的模型呢？

* ***分析与解答***

    ​		使用SMO算法训练的线性分类器并不一定能得到训练误差为0的模型。这是由于我们的优化目标改变了，并不再是使训练误差最小。考虑带松弛变量的SVM模型优化的目标函数所包含的两项：$C\sum\limits_{i=1}^{m}\zeta_i\frac{1}{2}{||w||}^2$,当我们的参数$C$选取较小的值时，后一项 （正则项）将占据优化的较大比重。这样，一个带有训练误差，但是参数较小的点将成为更优的结果。一个简单的特例是，当$C$取0时，$w$也取0即可达到优化目标，但是显然此时***我们的训练误差不一定能达到0***。

## 逻辑回归

逻辑回归(Logistic Regression)可以说是机器学习领域最基础也是最常用的模型，逻辑回归的原理推导以及扩展应用几乎是算法工程师的必备技能。

* ***知识点***
  
* 逻辑回归
    * 线性回归
    * 多标签分类
    * Softmax
    
* ***问题1***(★★☆☆☆)
    
* <font color=red>逻辑回归相比于线性回归，有何异同？</font>
    
* ***分析与解答***

    ​		首先，逻辑回归处理的是分类问题，线性回归处理的是回归问题，这是两者的最本质的 区别。逻辑回归中，因变量取值是一个二元分布，模型学习得出的是**$E[y|x;\theta]$**，即给定自变量和超参数后，得到因变量的期望，并基于此期望来处理预测分类问题。而线性回归中实际上求解的是**$y'=\theta^Tx$**，是对我们假设的真实关系的一个近似，其中$\theta$代表误差项，我们使用这个近似项来处理回归问题。

    ​		实际上，将逻辑回归的公式进行整理，我们可以得到**$log\frac{p}{1-p}=\theta^Tx$**，其中$p=P(y=1|x)$，也就是将给定输入**$x$**预测为正样本的概率。

    ​		我们均认为$y$是因变量，而非$\frac{p}{1-p}$，这便引出逻辑回归与线性回归最大的区别，即逻辑回归中的因变量为离散的，而线性回归中的因变量是连续的。并且在自变量$x$与超参数$θ$确定的情况下，逻辑回归可以看作广义线性模型（Generalized Linear Models）在因变量$y$服从二元分布时的一个特殊情况；而使用最小二乘法求解线性回归时，我们认为因变量$y$服从正态分布。 当

    ​		然逻辑回归和线性回归也不乏相同之处，首先我们可以认为二者都使用了极大似然估计来对训练样本进行建模。线性回归使用最小二乘法，实际上就是在自变量$x$与超参数$θ$确定，因变量$y$服从正态分布的假设下，使用极大似然估计的一个化简；而逻辑回归中通过对似然函数$L(\theta)=\prod\limits_{i=1}^{N}P(y_i|x_i;\theta)=\prod\limits_{i=1}^{N}(\pi(x_i))^{(y_i)}(1-\pi(x_i))^{1-y_i}$的学习，得到最佳参数$\theta$。另外，二者在求解超参数的过程中，都可以使用梯度下降的方法，这也是监督学习中一 个常见的相似之处。

* ***问题2***(★★★☆☆)

    * <font color=red>当使用逻辑回归处理多标签的分类问题时，有哪些常见做 法，分别应用于哪些场景，它们之间又有怎样的关系？</font>

* ***分析与解答***

    ​		使用哪一种办法来处理多分类的问题取决于具体问题的定义。首先，如果一个样本只对应于一个标签，我们可以假设每个样本属于不同标签的概率服从于几何分布，使用多项逻辑回归(Softmax Regression)来进行分类：
    $$
    h_{\theta}(x)=
    \left[\begin{matrix}
      p(y=1|x;\theta) \\
       p(y=2|x;\theta)  \\
       .\\
       .\\
       .\\
       p(y=2|x;\theta) 
    \end{matrix}\right]
    =\frac{1}{\sum\limits_{j=1}^{k}e^{\theta_j^T x}}\left[\begin{matrix}
    e^{\theta_1^T x}\\
    e^{\theta_2^T x}\\
    .\\
    .\\
    .\\
    e^{\theta_k^T x}
    \end{matrix}\right]
    $$
    其中$(\theta_1,\theta_2,...,\theta_k)\in R^n$为模型的参数$\frac{1}{\sum\limits_{j=1}^{k}e^{\theta_j^T x}}$可以看作是对概率的归一化，为了方便起见，我们将$\{\theta_1,\theta_2,...,\theta_k\}$这$k$个列向量按顺序排列形成$n×k$维矩阵，写作$θ$，表示整个参 数集。一般来说，多项逻辑回归具有参数冗余的特点，即将$\{\theta_1,\theta_2,...,\theta_k\}$同时加减一个向量 后预测结果不变。特别地，当类别数为2时:
    $$
    h_{\theta}(x)=\frac{1}{e^{\theta_1^T x}+e^{\theta_2^T x}}
    \left[\begin{matrix}
      e^{\theta_1^T x} \\
       e^{\theta_2^T x}  \\
    \end{matrix}\right]
    $$
    ​		 利用参数冗余的特点，我们将所有参数减去$θ_1$，式(34)变为 :
    $$
    h_{\theta}(x)=\frac{1}{e^{\theta_0^T x}+e^{(\theta_2^T -\theta_1^T ) x}}
    \left[\begin{matrix}
      e^{0.x} \\
       e^{(\theta_2^T -\theta_1^T )  x}  \\
    \end{matrix}\right]=\left[\begin{matrix}
      \frac{1}{1+ e^{\theta^T x}} \\
      1- \frac{1}{1+ e^{\theta^T x}}  \\
    \end{matrix}\right]
    $$
    ​		其中$\theta =\theta_2 - \theta_1$ 。而整理后的式子与逻辑回归一致。因此，多项逻辑回归实际上是二分类逻辑回归在多标签分类下的一种拓展。 

    ​		当存在样本可能属于多个标签的情况时，我们可以训练$k$个二分类的逻辑回归分类器。 第$i$个分类器用以区分每个样本是否可以归为第$i$类，训练该分类器时，需要把标签重新整理为“第$i$类标签”与“非第$i$类标签”两类。通过这样的办法，我们就解决了每个样本可能拥有多 个标签的情况。

## 决策树

决策树是一种自上而下，对数据样本进行树形分类的过程，由结点和有向边组成。结点分为内部结点和叶结点，其中每个内部结点表示一个特征或属性，叶结点表示类别。从顶部根结点开始，所有样本聚在一起。经过根结点的划分，样本被分到不同的子结点中。再根据子结点的特征进一步划分，直至所有样本都被归到某一个类别（即叶结点）中，一般而言，决策树的生成包含了特征选择、树的构造、树的剪枝三个过程。常用决策树分类：ID3、C4.5、CART

* ***知识点***
    
* 信息论
    * 树形数据结构
    * 优化理论
    
* ***问题1***(★★☆☆☆)

    * <font color=red>决策树有哪些常用的启发函数？</font>

* ***分析与解答***

    * **ID3**——最大信息增益

        ​		对于样本集合D，类别数为K，数据集D的经验熵表示为:
        $$
        H(D)=-\sum\limits_{k=1}^{k}\frac{|C_k|}{D}log_{2}^{\frac{|C_k|}{D}}
        $$
        ​		其中$C_k$是样本集合$D$中属于第$k$类的样本子集，$|C_k |$表示该子集的元素个数，$|D|$表示样本集合的元素个数。

        ​		然后计算某个特征$A$对于数据集$D$的经验条件熵$H(D|A)$为:
        $$
        H(D|A)=\sum\limits_{i=1}^{n}\frac{D_i}{D}H(D_i)=\sum\limits_{i=1}^{n}\frac{D_i}{D}
        \left(\begin{matrix}
        {-\sum\limits_{k=1}^{k}\frac{|D_{ik}|}{|D_i|}log_2^\frac{|D_{ik}|}{|D_i|}}
        \end{matrix}
        \right)
        $$
        ​		其中，$D_i$表示$D$中特征A取第$i$个值的样本子集，$D_{ik}$表示$D_i$中属于第$k$类的样本子集

        ​		于是信息增益g(D,A)可以表示为二者之差，可得:
        $$
        g(D,A)=H(D)-H(D|A)
        $$

    *  **C4.5**——最大信息增益比

        ​		特征A对于数据集D的信息增益比定义为:
        $$
        g_R(D,A)=\frac{g(D,A)}{H_A(D)}
        $$
        ​		其中$H_A(D)=-\sum\limits_{i=1}^{n} \frac{|D_i|}{|D|}log_2^{\frac{|D_i|}{|D|}}$称为数据集D关于A的取值熵。

    * **CART**——最大基尼指数（Gini）

        ​		Gini描述的是数据的纯度，与信息熵含义类似。
        $$
        Gini(D)=1-\sum\limits_{k=1}^{n}\left(\begin{matrix}
        \frac{|C_k|}{|D|}
        \end{matrix}
        \right)^2
        $$
        ​		CART在每一次迭代中选择基尼指数最小的特征及其对应的切分点进行分类。但与ID3、 C4.5不同的是，CART是一颗二叉树，采用二元切割法，每一步将数据按特征A的取值切成两 份，分别进入左右子树。特征A的Gini指数定义为:
        $$
        Gini(D|A)=\sum\limits_{i=1}^{n}\frac{|D_i|}{|D|}Gini(D_i)
        $$

    * 对比

        * **ID3**是采用信息增益作为评价标准
        * **C4.5**通过引入信息增益比，一定程度上对取值比较多的特征进行惩罚，避免ID3出现过拟合的特性，提升决策树的泛化能力。
        * **ID3**只能处理离散型变量
        * **C4.5**和**CART**都可以处理连续型变量
        * **ID3**对样本 特征缺失值比较敏感，而**C4.5**和**CART**可以对缺失值进行不同方式的处理；
        * **ID3**和**C4.5**可以在每个结点上产生出多叉分支，且每个特征在层级之间不会复用，
        * **CART**每个结点只会产生两个分支，因此最后会形成一颗二叉树，且每个特征可以被重复使用
        * **ID3**和**C4.5**通过剪枝来权衡树的准确性与泛化能力，**CART**利用全部数据发现所有可能的树结构进行对比

* ***问题2***(★★★☆☆)

    * <font color=red>如何对决策树进行剪枝？</font>

        ​		一颗完全生长的决策树会产生过拟合，用它进行预测时，在测试集上效果会很差，因此需要对决策树进行剪枝，提升模型的泛化能力。

        ​		决策树剪枝通常有两种方法：预剪枝(Pre-Pruning)和后剪枝(Post-Pruning)

        * **预剪枝**：即在生成决策树的过程中提前停止树的增长
        * **后剪枝**：是在已生成的过拟合 决策树上进行剪枝，得到简化版的剪枝决策树

* ***分析与解答***

    * **预剪枝**

        ​		预剪枝的核心思想是在树中结点进行扩展之前，先计算当前的划分是否能带来模型泛化能力的提升，如果不能，则不再继续生长子树。此时可能存在不同类别的样本同时存于结点中，按照多数投票的原则判断该结点所属类别。预剪枝对于何时停止决策树的生长有以下几种方法：

        * 当树到达一定深度的时候，停止树的生长
        * 当到达当前结点的样本数量小于某个阈值的时候，停止树的生长
        * 计算每次分裂对测试集的准确度提升，当小于某个阈值的时候，不再继续扩展

        ​        预剪枝具有思想直接、算法简单、效率高等特点，适合解决大规模问题。但如何准确地估计何时停止树的生长（即上述方法中的深度或阈值），针对不同问题会有很大差别，需要一定经验判断。且预剪枝存在一定局限性，有欠拟合的风险，虽然当前的划分会导致测试集准确率降低，但在之后的划分中，准确率可能会有显著上升

    * **后剪枝**

        ​		后剪枝的核心思想是让算法生成一棵完全生长的决策树，然后从最底层向上计算是否剪枝。剪枝过程将子树删除，用一个叶子结点替代，该结点的类别同样按照多数投票的原则进行判断。同样地，后剪枝也可以通过在测试集上的准确率进行判断，如果剪枝过后准确率有所提升，则进行剪枝。相比于预剪枝，后剪枝方法通常可以得到泛化能力更强的决策树，但时间开销会更大

        * 常用后剪枝方法：

            * 错误率降低剪枝(Reduced Error Pruning，REP)
            * 悲观剪枝(Pessimistic Error Pruning，PEP)
            * 代价复杂度剪枝(Cost Complexity Pruning，CCP)
            * 最小误差剪枝(Minimum Error Pruning，MEP)
            * CVP(Critical Value Pruning)
            * OPP(Optimal Pruning)

        * 代价复杂剪枝主要包含以下两个步骤

            * A:从完整决策树$T_0$开始，生成一个子树序列$\{T_0,T_1,T_2,...,T_n\}$，其中$T_{i+1}$由$T_i$生成，$T_n$为树的根结点

            * B:在子树序列中，根据真实误差选择最佳的决策树

                从$T_0$开始，裁剪$T_i$中关于训练数据集合误差增加最小的分支以得到$T_{i+1}$。具体地，当一棵树$T$在结点$t$处剪枝时，它的误差增加可以用$R(t)−R(T_t)$表示，其中$R(t)$表示进行剪枝之后的该结点误差，$R(T_t)$表示未进行剪枝时子树$T_t$的误差。考虑到树的复杂性因素，我们用$|L(T_t )|$表示子树$T_t$的叶子结点个数，则树在结点$t$处剪枝后的误差增加率为:
                $$
                \alpha=\frac{R(t)-R(T_t)}{|L(T_t)|-1}
                $$
                在得到$T_i$后，我们每步选择$α$最小的结点进行相应剪枝.

                ​		代价复杂度剪枝使用交叉验证策略时，不需要测试数据集，精度与REP差不多，但形成 的树复杂度小。而从算法复杂度角度，由于生成子树序列的时间复杂度与原始决策树的非叶 结点个数呈二次关系，导致算法相比REP、PEP、MEP等线性复杂度的后剪枝方法，运行时 间开销更大.

# 降维

## PCA最大化方差理论

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)
* <font color=red>准</font>
    
* ***分析与解答***

## PCA最小平方误差理论

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 线性判别分析

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 线性判别分析与主成分分析

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

# 非监督学习

## K均值聚类

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 高斯混合模型

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 自组织映射神经网络

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 聚类算法的评估

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

# 概率图模型

## 概率图模型的联合概率分布

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 概率图表示

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 生成式模型与判别式模型

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 马尔可夫模型

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 主题模型

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

# 优化算法

## 有监督学习的损失函数

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 机器学习中的优化问题

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 经典优化算法

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 梯度验证

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 随机梯度下降法

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 随机梯度下降法的加速

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## L1正则化与稀疏性

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

# 采样

## 采样的作用

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 均匀分布随机数

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 常见的采样方法

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 高斯分布的采样

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 马尔可夫蒙特卡洛采样法

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 贝叶斯网络采样

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 不均衡样本的重采样

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

# 前向神经网络

## 多层感知机与布尔函数

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 深度神经网络中的激活函数

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 多层感知机的反向传播算法

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 神经网络训练技巧

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 深度卷积神经网络

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 深度残差网络

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

# 循环神经网络

## 循环升级网络和卷积神经网络

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 循环神经网络的梯度消失问题

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 循环神经网络中的激活函数

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 长短期记忆模型

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## Seq2Seq模型

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 注意力机制

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

# 强化学习

## 强化学习基础

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 视频游戏里的强化学习

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 策略梯度

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 探索与利用

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

# 集成学习

## 集成学习的种类

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 集成学习的步骤和例子

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 基分类器

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 偏差与误差

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## 梯度提升决策树的基本原理

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## XGBoost与GBDT的联系与区别

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

# 生成对抗神经网络

## 初始GANs的密码

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## WGAN：抓住低维的幽灵

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## DCGAN：当GANs遇上卷积

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## ALI：包揽推断业务

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## IRGAN：生成离散样本

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***

## SeqGAN：生成文本序列

* ***知识点***
    * 准

* ***问题1***(★☆☆☆☆)

    * <font color=red>准</font>

* ***分析与解答***



